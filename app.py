from langchain_upstage import ChatUpstage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
import streamlit as st
from transformers import pipeline

st.set_page_config(
         page_title="ì¤‘ê°„í‰ê°€ ì±—ë´‡",
         page_icon="ğŸ¤–",
     )
st.title("ë­ì²´ì¸ ë©€í‹°í„´ ì±—ë´‡")

#-------------- ì´ˆê¸° ì„¸íŒ…
if "chain" not in st.session_state:
    api_key = st.secrets["UPSTAGE_API_KEY"]
    
    if "UPSTAGE_API_KEY" not in st.secrets:
        st.error("UPSTAGE_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        st.stop()
        
    chat = ChatUpstage(api_key=api_key, model="solar-mini")

    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                "You are a helpful assistant. Answer all questions to the best of your ability. You must anwer with Korean.",
            ),
            MessagesPlaceholder("messages"), # ì´ì „ì— ë‚˜ëˆ´ë˜ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°
        ]
    )

    # promptì™€ chat(ì–¸ì–´ ëª¨ë¸)ì„ ì—°ê²°í•˜ì—¬ í•˜ë‚˜ì˜ ì²˜ë¦¬ íë¦„(chain)ì„ ë§Œë“œëŠ” pipe(|)
    st.session_state.chain = prompt | chat # ë­ì²´ì¸ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë¬¸ë²•
    # ë©”ì„¸ì§€ ì—†ìœ¼ë©´ ë©”ì„¸ì§€ ì´ˆê¸°í™”(chainì´ ì—†ìœ¼ë©´ messageë„ ì—†ìœ¼ë‹ˆ)
    st.session_state.messages = []
#-----------------    

# ê¸°ì¡´ ë©”ì„¸ì§€ í‘œì‹œ # ì§ˆë¬¸í•  ë•Œë§ˆë‹¤ ì´ì „ ë©”ì„¸ì§€ ì‚¬ë¼ì§€ê³  ìƒˆë¡œìš´ ë‹µ ëœ¨ëŠ” ê±° ë°©ì§€
for message in st.session_state.messages:
    with st.chat_message(message['role']):
        st.markdown(message['content'])
        

# íŒŒì´í”„ë¼ì¸ ìºì‹œí™”(ìµœì´ˆ í•œ ë²ˆë§Œ ë¡œë“œ) -> ê°ì •ë¶„ì„ ëª¨ë¸ì„ ê³„ì† ë¡œë“œí•˜ëŠ” ê±¸ ë°©ì§€
# í—ˆê¹…í˜ì´ìŠ¤ ê°ì •ë¶„ì„ íŒŒì´í”„ë¼ì¸
@st.cache_resource
def sentimental_pipeline():
    return pipeline("sentiment-analysis",model="monologg/koelectra-base-finetuned-nsmc")

if user_prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”."):
    st.session_state.messages.append({"role": "user","content": user_prompt})
    
    with st.chat_message("user"):
        st.markdown(user_prompt)
          
    with st.chat_message("assistant"):
        try:
            result = st.session_state.chain.stream({
                "messages": st.session_state.messages
            })
    
            # st.write_stream ì£¼ì–´ì§„ ì‹œí€€ìŠ¤ë¥¼ ë°˜ë³µí•˜ë©° ëª¨ë“  ì²­í¬ë¥¼ ì•±ì— ì”€
            # -> ë¬¸ìì—´ ì²­í¬ëŠ” íƒ€ìê¸° íš¨ê³¼ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ì„±ë¨
            full_response = st.write_stream(result)
            
            try:
            # ê°ì • ë¶„ì„
                sentiment_analysis = sentimental_pipeline() # ìºì‹œëœ íŒŒì´í”„ë¼ì¸ ê°€ì ¸ì˜´
                senti_result = sentiment_analysis(full_response)
                # ë¶„ì„í•œ ê°ì • ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤Œ
                st.info(f"ìœ„ ë‹µë³€ì˜ ê°ì •ì€: {senti_result[0]['label']}")
            except Exception as e:
                st.error(f"ê°ì • ë¶„ì„ ì¤‘ ì—ëŸ¬: {e}")
            
            st.session_state.messages.append({"role": "assistant","content": full_response})
            
        except Exception as e:
            st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì—ëŸ¬: {e}")